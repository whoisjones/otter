{
    "run_name": "thai-finerweb-run",
    "token_encoder": "google-bert/bert-base-multilingual-cased",
    "type_encoder": "google-bert/bert-base-multilingual-cased",
    "dataset_name": "thainer",
    "annotation_format": "tokens",
    "loss_masking": "subwords",
    "train_file": "/vol/tmp/goldejon/ner/data/finerweb_splitted/tha.jsonl",
    "validation_file": "/vol/tmp/goldejon/ner/data/thainer/validation.jsonl",
    "test_file": "/vol/tmp/goldejon/ner/data/thainer/test.jsonl",
    "output_dir": "/vol/tmp/goldejon/ner/thainer-finerweb",
    "per_device_train_batch_size": 4,
    "per_device_eval_batch_size": 4,
    "loss_fn": "bce",
    "focal_alpha": 0.75,
    "focal_gamma": 2.0,
    "learning_rate": 3e-05,
    "max_steps": 3000,
    "eval_steps": 500,
    "max_seq_length": 512,
    "warmup_steps": 300,
    "seed": 42,
    "max_span_length": 30,
    "dropout": 0.1,
    "linear_hidden_size": 384,
    "span_width_embedding_size": 128,
    "init_temperature": 0.03,
    "start_loss_weight": 0.15,
    "end_loss_weight": 0.15,
    "span_loss_weight": 0.7,
    "save_total_limit": 2,
    "type_encoder_pooling": "cls",
    "fp16": true,
    "do_train": true,
    "do_eval": true,
    "do_predict": true,
    "prediction_threshold": 0.1
}
  
  
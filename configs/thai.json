{
  "run_name": "thai-ner-base-run",
  "token_encoder": "Qwen/Qwen3-Embedding-0.6B",
  "type_encoder": "bert-base-uncased",
  "dataset_name": "thainer",
  "annotation_format": "text",
  "train_file": "/vol/tmp/goldejon/ner/data/thainer/train.jsonl",
  "validation_file": "/vol/tmp/goldejon/ner/data/thainer/validation.jsonl",
  "test_file": "/vol/tmp/goldejon/ner/data/thainer/test.jsonl",
  "output_dir": "/vol/tmp/goldejon/ner/thainer",
  "per_device_train_batch_size": 4,
  "per_device_eval_batch_size": 4,
  "learning_rate": 3e-05,
  "max_steps": 3000,
  "eval_steps": 500,
  "max_seq_length": 512,
  "warmup_steps": 300,
  "seed": 42,
  "max_span_length": 30,
  "dropout": 0.1,
  "linear_hidden_size": 128,
  "init_temperature": 0.01,
  "start_loss_weight": 0.1,
  "end_loss_weight": 0.1,
  "span_loss_weight": 0.8,
  "save_total_limit": 2,
  "type_encoder_pooling": "cls",
  "fp16": true,
  "do_train": true,
  "do_eval": true,
  "do_predict": true,
  "prediction_threshold": 0.4,
  "positive_class_weight": 3.0
}

